{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (SparkSession\n",
    "        .Builder()\n",
    "        .appName(\"Python Spark SQL basic example\")\n",
    "        .master(\"local[2]\")\n",
    "        .config(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-aws:2.7.0\") \\\n",
    "        .getOrCreate()\n",
    ")\n",
    "spark.sparkContext.setLogLevel('WARN')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Song Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 12:===============================================>      (414 + 2) / 466]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- artist_id: string (nullable = true)\n",
      " |-- artist_latitude: double (nullable = true)\n",
      " |-- artist_location: string (nullable = true)\n",
      " |-- artist_longitude: double (nullable = true)\n",
      " |-- artist_name: string (nullable = true)\n",
      " |-- duration: double (nullable = true)\n",
      " |-- num_songs: long (nullable = true)\n",
      " |-- song_id: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- year: long (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_songs = spark.read.json(\"./data/song_data/A/*/*/*.json\")\n",
    "df_songs.printSchema()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The infered schema looks good. We can create one to make it more explicit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import (\n",
    "    StructType,\n",
    "    StructField, \n",
    "    StringType, \n",
    "    DoubleType,\n",
    "    LongType,\n",
    "    IntegerType\n",
    ")\n",
    "# create a schema simialr to this\n",
    "# |-- artist_id: string (nullable = true)\n",
    "# |-- artist_latitude: double (nullable = true)\n",
    "# |-- artist_location: string (nullable = true)\n",
    "# |-- artist_longitude: double (nullable = true)\n",
    "# |-- artist_name: string (nullable = true)\n",
    "# |-- duration: double (nullable = true)\n",
    "# |-- num_songs: long (nullable = true)\n",
    "# |-- song_id: string (nullable = true)\n",
    "# |-- title: string (nullable = true)\n",
    "# |-- year: long (nullable = true)\n",
    "songs_schema = StructType([\n",
    "    StructField('artist_id', StringType()),\n",
    "    StructField('artist_latitude', DoubleType()),\n",
    "    StructField('artist_location', StringType()),\n",
    "    StructField('artist_longitude', DoubleType()),\n",
    "    StructField('artist_name', StringType()),\n",
    "    StructField('duration', DoubleType()),\n",
    "    StructField('num_songs', IntegerType()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_songs = spark.read.json(\"./data/song_data/A/*/*/*.json\", \n",
    "                           schema = songs_schema)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Songs Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist_id</th>\n",
       "      <th>artist_latitude</th>\n",
       "      <th>artist_location</th>\n",
       "      <th>artist_longitude</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>duration</th>\n",
       "      <th>num_songs</th>\n",
       "      <th>song_id</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AR4T2IF1187B9ADBB7</td>\n",
       "      <td>63.96027</td>\n",
       "      <td>&lt;a href=\"http://billyidol.net\" onmousedown='Un...</td>\n",
       "      <td>10.22442</td>\n",
       "      <td>Billy Idol</td>\n",
       "      <td>233.22077</td>\n",
       "      <td>1</td>\n",
       "      <td>SOVIYJY12AF72A4B00</td>\n",
       "      <td>The Dead Next Door (Digitally Remastered 99)</td>\n",
       "      <td>1983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AR4T2IF1187B9ADBB7</td>\n",
       "      <td>63.96027</td>\n",
       "      <td>&lt;a href=\"http://billyidol.net\" onmousedown='Un...</td>\n",
       "      <td>10.22442</td>\n",
       "      <td>Billy Idol</td>\n",
       "      <td>287.92118</td>\n",
       "      <td>1</td>\n",
       "      <td>SOVYXYL12AF72A3373</td>\n",
       "      <td>Rebel Yell (1999 Digital Remaster)</td>\n",
       "      <td>1983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ARQ846I1187B9A7083</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yvonne S. Moriarty / Walt Fowler / Ladd McInto...</td>\n",
       "      <td>196.04853</td>\n",
       "      <td>1</td>\n",
       "      <td>SOEPTVC12A67ADD0DA</td>\n",
       "      <td>To Zucchabar [\"Gladiator\" - Music from the Mot...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AR4T2IF1187B9ADBB7</td>\n",
       "      <td>63.96027</td>\n",
       "      <td>&lt;a href=\"http://billyidol.net\" onmousedown='Un...</td>\n",
       "      <td>10.22442</td>\n",
       "      <td>Billy Idol</td>\n",
       "      <td>247.53587</td>\n",
       "      <td>1</td>\n",
       "      <td>SOLQYSZ12AB0181F97</td>\n",
       "      <td>Mony Mony (Live)</td>\n",
       "      <td>1987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AR3TZ691187FB3DBB1</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>Russell Watson / Pino Palladino / Robbie McInt...</td>\n",
       "      <td>273.44934</td>\n",
       "      <td>1</td>\n",
       "      <td>SOVPFJK12A6701CB16</td>\n",
       "      <td>Barcelona - (Friends until the end)</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            artist_id  artist_latitude  \\\n",
       "0  AR4T2IF1187B9ADBB7         63.96027   \n",
       "1  AR4T2IF1187B9ADBB7         63.96027   \n",
       "2  ARQ846I1187B9A7083              NaN   \n",
       "3  AR4T2IF1187B9ADBB7         63.96027   \n",
       "4  AR3TZ691187FB3DBB1              NaN   \n",
       "\n",
       "                                     artist_location  artist_longitude  \\\n",
       "0  <a href=\"http://billyidol.net\" onmousedown='Un...          10.22442   \n",
       "1  <a href=\"http://billyidol.net\" onmousedown='Un...          10.22442   \n",
       "2                                                                  NaN   \n",
       "3  <a href=\"http://billyidol.net\" onmousedown='Un...          10.22442   \n",
       "4                                                                  NaN   \n",
       "\n",
       "                                         artist_name   duration  num_songs  \\\n",
       "0                                         Billy Idol  233.22077          1   \n",
       "1                                         Billy Idol  287.92118          1   \n",
       "2  Yvonne S. Moriarty / Walt Fowler / Ladd McInto...  196.04853          1   \n",
       "3                                         Billy Idol  247.53587          1   \n",
       "4  Russell Watson / Pino Palladino / Robbie McInt...  273.44934          1   \n",
       "\n",
       "              song_id                                              title  year  \n",
       "0  SOVIYJY12AF72A4B00       The Dead Next Door (Digitally Remastered 99)  1983  \n",
       "1  SOVYXYL12AF72A3373                 Rebel Yell (1999 Digital Remaster)  1983  \n",
       "2  SOEPTVC12A67ADD0DA  To Zucchabar [\"Gladiator\" - Music from the Mot...     0  \n",
       "3  SOLQYSZ12AB0181F97                                   Mony Mony (Live)  1987  \n",
       "4  SOVPFJK12A6701CB16                Barcelona - (Friends until the end)  2000  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_songs.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs_tablo = (\n",
    "    df_songs.\n",
    "    select('song_id', 'title', 'artist_id', 'year', 'duration')\n",
    "    .drop_duplicates([\"song_id\"])\n",
    ")\n",
    "songs_tablo.write.parquet(path = \"songs_table\",\n",
    "                          partitionBy= [\"year\", \"artist_id\"])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Artist Table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artists_table = (\n",
    "    df_songs\n",
    "    .select(\"artist_id\", \"artist_name\", \"artist_location\", \"artist_latitude\", \"artist_longitude\")\n",
    "    .withColumnRenamed(\"artist_name\", \"name\")\n",
    "    .drop_duplicates([\"artist_id\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artists_table.write.parquet(path = \"path\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_logs = spark.read.json(\"./data/log_data/2018/11/*.json\")\n",
    "df_logs.printSchema()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Log Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- artist: string (nullable = true)\n",
      " |-- auth: string (nullable = true)\n",
      " |-- firstName: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- itemInSession: long (nullable = true)\n",
      " |-- lastName: string (nullable = true)\n",
      " |-- length: double (nullable = true)\n",
      " |-- level: string (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- method: string (nullable = true)\n",
      " |-- page: string (nullable = true)\n",
      " |-- registration: double (nullable = true)\n",
      " |-- sessionId: long (nullable = true)\n",
      " |-- song: string (nullable = true)\n",
      " |-- status: long (nullable = true)\n",
      " |-- ts: long (nullable = true)\n",
      " |-- userAgent: string (nullable = true)\n",
      " |-- userId: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_logs = spark.read.json(\"./data/log_data/2018/11/*.json\")\n",
    "df_logs.printSchema()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some datatypes are not accurate, so, we can\n",
    "* Fix them individually\n",
    "* Or enforce a schema to fix them when reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import (\n",
    "    StructType,\n",
    "    StructField, \n",
    "    StringType, \n",
    "    DoubleType,\n",
    "    LongType,\n",
    "    TimestampType,\n",
    "    IntegerType\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # We want a schema like this one\n",
    "#  |-- artist: string (nullable = true)\n",
    "#  |-- auth: string (nullable = true)\n",
    "#  |-- firstName: string (nullable = true)\n",
    "#  |-- gender: string (nullable = true)\n",
    "#  |-- itemInSession: long (nullable = true)\n",
    "#  |-- lastName: string (nullable = true)\n",
    "#  |-- length: double (nullable = true)\n",
    "#  |-- level: string (nullable = true)\n",
    "#  |-- location: string (nullable = true)\n",
    "#  |-- method: string (nullable = true)\n",
    "#  |-- page: string (nullable = true)\n",
    "#  |-- registration: double (nullable = true)\n",
    "#  |-- sessionId: long (nullable = true)\n",
    "#  |-- song: string (nullable = true)\n",
    "#  |-- status: long (nullable = true)\n",
    "#  |-- ts: long (nullable = true)\n",
    "#  |-- userAgent: string (nullable = true)\n",
    "#  |-- userId: string (nullable = true)\n",
    "logs_schema = StructType([\n",
    "    StructField(\"artist\", StringType()),\n",
    "    StructField(\"auth\", StringType()),\n",
    "    StructField(\"firstName\", StringType()),\n",
    "    StructField(\"gender\", StringType()),\n",
    "    StructField(\"itemInSession\", LongType()),\n",
    "    StructField(\"lastName\", StringType()),\n",
    "    StructField(\"length\", DoubleType()),\n",
    "    StructField(\"level\", StringType()),\n",
    "    StructField(\"location\", StringType()),\n",
    "    StructField(\"method\", StringType()),\n",
    "    StructField(\"page\", StringType()),\n",
    "    StructField(\"registration\", TimestampType()),\n",
    "    StructField(\"sessionId\", LongType()),\n",
    "    StructField(\"song\", StringType()),\n",
    "    StructField(\"status\", LongType()),\n",
    "    StructField(\"ts\", TimestampType()),\n",
    "    StructField(\"userAgent\", StringType()),\n",
    "    StructField(\"userId\", StringType())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_logs = spark.read.json(\"./data/log_data/2018/11/*.json\",\n",
    "                         schema=logs_schema)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "year 50841 is out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[70], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_logs\u001b[39m.\u001b[39;49mlimit(\u001b[39m5\u001b[39;49m)\u001b[39m.\u001b[39;49mtoPandas()\n",
      "File \u001b[0;32m/workspaces/spark-project/.venv/lib/python3.10/site-packages/pyspark/sql/pandas/conversion.py:208\u001b[0m, in \u001b[0;36mPandasConversionMixin.toPandas\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    205\u001b[0m             \u001b[39mraise\u001b[39;00m\n\u001b[1;32m    207\u001b[0m \u001b[39m# Below is toPandas without Arrow optimization.\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m pdf \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame\u001b[39m.\u001b[39mfrom_records(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollect(), columns\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns)\n\u001b[1;32m    209\u001b[0m column_counter \u001b[39m=\u001b[39m Counter(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns)\n\u001b[1;32m    211\u001b[0m corrected_dtypes: List[Optional[Type]] \u001b[39m=\u001b[39m [\u001b[39mNone\u001b[39;00m] \u001b[39m*\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mschema)\n",
      "File \u001b[0;32m/workspaces/spark-project/.venv/lib/python3.10/site-packages/pyspark/sql/dataframe.py:1217\u001b[0m, in \u001b[0;36mDataFrame.collect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1215\u001b[0m \u001b[39mwith\u001b[39;00m SCCallSiteSync(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sc):\n\u001b[1;32m   1216\u001b[0m     sock_info \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jdf\u001b[39m.\u001b[39mcollectToPython()\n\u001b[0;32m-> 1217\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39;49m(_load_from_socket(sock_info, BatchedSerializer(CPickleSerializer())))\n",
      "File \u001b[0;32m/workspaces/spark-project/.venv/lib/python3.10/site-packages/pyspark/serializers.py:152\u001b[0m, in \u001b[0;36mFramedSerializer.load_stream\u001b[0;34m(self, stream)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    151\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 152\u001b[0m         \u001b[39myield\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_with_length(stream)\n\u001b[1;32m    153\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mEOFError\u001b[39;00m:\n\u001b[1;32m    154\u001b[0m         \u001b[39mreturn\u001b[39;00m\n",
      "File \u001b[0;32m/workspaces/spark-project/.venv/lib/python3.10/site-packages/pyspark/serializers.py:174\u001b[0m, in \u001b[0;36mFramedSerializer._read_with_length\u001b[0;34m(self, stream)\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(obj) \u001b[39m<\u001b[39m length:\n\u001b[1;32m    173\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mEOFError\u001b[39;00m\n\u001b[0;32m--> 174\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mloads(obj)\n",
      "File \u001b[0;32m/workspaces/spark-project/.venv/lib/python3.10/site-packages/pyspark/serializers.py:472\u001b[0m, in \u001b[0;36mCloudPickleSerializer.loads\u001b[0;34m(self, obj, encoding)\u001b[0m\n\u001b[1;32m    471\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mloads\u001b[39m(\u001b[39mself\u001b[39m, obj, encoding\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbytes\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 472\u001b[0m     \u001b[39mreturn\u001b[39;00m cloudpickle\u001b[39m.\u001b[39;49mloads(obj, encoding\u001b[39m=\u001b[39;49mencoding)\n",
      "File \u001b[0;32m/workspaces/spark-project/.venv/lib/python3.10/site-packages/pyspark/sql/types.py:2007\u001b[0m, in \u001b[0;36m_create_row_inbound_converter.<locals>.<lambda>\u001b[0;34m(*a)\u001b[0m\n\u001b[1;32m   2006\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_create_row_inbound_converter\u001b[39m(dataType: DataType) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Callable:\n\u001b[0;32m-> 2007\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mlambda\u001b[39;00m \u001b[39m*\u001b[39ma: dataType\u001b[39m.\u001b[39;49mfromInternal(a)\n",
      "File \u001b[0;32m/workspaces/spark-project/.venv/lib/python3.10/site-packages/pyspark/sql/types.py:1018\u001b[0m, in \u001b[0;36mStructType.fromInternal\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m   1015\u001b[0m values: Union[Tuple, List]\n\u001b[1;32m   1016\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_needSerializeAnyField:\n\u001b[1;32m   1017\u001b[0m     \u001b[39m# Only calling fromInternal function for fields that need conversion\u001b[39;00m\n\u001b[0;32m-> 1018\u001b[0m     values \u001b[39m=\u001b[39m [\n\u001b[1;32m   1019\u001b[0m         f\u001b[39m.\u001b[39mfromInternal(v) \u001b[39mif\u001b[39;00m c \u001b[39melse\u001b[39;00m v\n\u001b[1;32m   1020\u001b[0m         \u001b[39mfor\u001b[39;00m f, v, c \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfields, obj, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_needConversion)\n\u001b[1;32m   1021\u001b[0m     ]\n\u001b[1;32m   1022\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1023\u001b[0m     values \u001b[39m=\u001b[39m obj\n",
      "File \u001b[0;32m/workspaces/spark-project/.venv/lib/python3.10/site-packages/pyspark/sql/types.py:1019\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1015\u001b[0m values: Union[Tuple, List]\n\u001b[1;32m   1016\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_needSerializeAnyField:\n\u001b[1;32m   1017\u001b[0m     \u001b[39m# Only calling fromInternal function for fields that need conversion\u001b[39;00m\n\u001b[1;32m   1018\u001b[0m     values \u001b[39m=\u001b[39m [\n\u001b[0;32m-> 1019\u001b[0m         f\u001b[39m.\u001b[39;49mfromInternal(v) \u001b[39mif\u001b[39;00m c \u001b[39melse\u001b[39;00m v\n\u001b[1;32m   1020\u001b[0m         \u001b[39mfor\u001b[39;00m f, v, c \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfields, obj, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_needConversion)\n\u001b[1;32m   1021\u001b[0m     ]\n\u001b[1;32m   1022\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1023\u001b[0m     values \u001b[39m=\u001b[39m obj\n",
      "File \u001b[0;32m/workspaces/spark-project/.venv/lib/python3.10/site-packages/pyspark/sql/types.py:667\u001b[0m, in \u001b[0;36mStructField.fromInternal\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    666\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfromInternal\u001b[39m(\u001b[39mself\u001b[39m, obj: T) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m T:\n\u001b[0;32m--> 667\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataType\u001b[39m.\u001b[39;49mfromInternal(obj)\n",
      "File \u001b[0;32m/workspaces/spark-project/.venv/lib/python3.10/site-packages/pyspark/sql/types.py:279\u001b[0m, in \u001b[0;36mTimestampType.fromInternal\u001b[0;34m(self, ts)\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfromInternal\u001b[39m(\u001b[39mself\u001b[39m, ts: \u001b[39mint\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m datetime\u001b[39m.\u001b[39mdatetime:\n\u001b[1;32m    277\u001b[0m     \u001b[39mif\u001b[39;00m ts \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    278\u001b[0m         \u001b[39m# using int to avoid precision loss in float\u001b[39;00m\n\u001b[0;32m--> 279\u001b[0m         \u001b[39mreturn\u001b[39;00m datetime\u001b[39m.\u001b[39;49mdatetime\u001b[39m.\u001b[39;49mfromtimestamp(ts \u001b[39m/\u001b[39;49m\u001b[39m/\u001b[39;49m \u001b[39m1000000\u001b[39;49m)\u001b[39m.\u001b[39mreplace(microsecond\u001b[39m=\u001b[39mts \u001b[39m%\u001b[39m \u001b[39m1000000\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: year 50841 is out of range"
     ]
    }
   ],
   "source": [
    "df_logs.limit(5).toPandas()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like we need to get our hands a little bit dirty. A quick fix using the schema didn't do it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- artist: string (nullable = true)\n",
      " |-- auth: string (nullable = true)\n",
      " |-- firstName: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- itemInSession: integer (nullable = true)\n",
      " |-- lastName: string (nullable = true)\n",
      " |-- length: double (nullable = true)\n",
      " |-- level: string (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- method: string (nullable = true)\n",
      " |-- page: string (nullable = true)\n",
      " |-- registration: long (nullable = true)\n",
      " |-- sessionId: integer (nullable = true)\n",
      " |-- song: string (nullable = true)\n",
      " |-- status: integer (nullable = true)\n",
      " |-- ts: long (nullable = true)\n",
      " |-- userAgent: string (nullable = true)\n",
      " |-- userId: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logs_schema = StructType([\n",
    "    StructField(\"artist\", StringType()),\n",
    "    StructField(\"auth\", StringType()),\n",
    "    StructField(\"firstName\", StringType()),\n",
    "    StructField(\"gender\", StringType()),\n",
    "    StructField(\"itemInSession\", IntegerType()),\n",
    "    StructField(\"lastName\", StringType()),\n",
    "    StructField(\"length\", DoubleType()),\n",
    "    StructField(\"level\", StringType()),\n",
    "    StructField(\"location\", StringType()),\n",
    "    StructField(\"method\", StringType()),\n",
    "    StructField(\"page\", StringType()),\n",
    "    StructField(\"registration\", LongType()),\n",
    "    StructField(\"sessionId\", IntegerType()),\n",
    "    StructField(\"song\", StringType()),\n",
    "    StructField(\"status\", IntegerType()),\n",
    "    StructField(\"ts\", LongType()),\n",
    "    StructField(\"userAgent\", StringType()),\n",
    "    StructField(\"userId\", IntegerType())\n",
    "])\n",
    "df_logs = spark.read.json(\"./data/log_data/2018/11/*.json\",\n",
    "                          schema=logs_schema)\n",
    "df_logs.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import from_unixtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>auth</th>\n",
       "      <th>firstName</th>\n",
       "      <th>gender</th>\n",
       "      <th>itemInSession</th>\n",
       "      <th>lastName</th>\n",
       "      <th>length</th>\n",
       "      <th>level</th>\n",
       "      <th>location</th>\n",
       "      <th>method</th>\n",
       "      <th>page</th>\n",
       "      <th>registration</th>\n",
       "      <th>sessionId</th>\n",
       "      <th>song</th>\n",
       "      <th>status</th>\n",
       "      <th>ts</th>\n",
       "      <th>userAgent</th>\n",
       "      <th>userId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Harmonia</td>\n",
       "      <td>Logged In</td>\n",
       "      <td>Ryan</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>Smith</td>\n",
       "      <td>655.77751</td>\n",
       "      <td>free</td>\n",
       "      <td>San Jose-Sunnyvale-Santa Clara, CA</td>\n",
       "      <td>PUT</td>\n",
       "      <td>NextSong</td>\n",
       "      <td>None</td>\n",
       "      <td>583</td>\n",
       "      <td>Sehr kosmisch</td>\n",
       "      <td>200</td>\n",
       "      <td>2018-11-15 00:30:26</td>\n",
       "      <td>\"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/5...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Prodigy</td>\n",
       "      <td>Logged In</td>\n",
       "      <td>Ryan</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>Smith</td>\n",
       "      <td>260.07465</td>\n",
       "      <td>free</td>\n",
       "      <td>San Jose-Sunnyvale-Santa Clara, CA</td>\n",
       "      <td>PUT</td>\n",
       "      <td>NextSong</td>\n",
       "      <td>None</td>\n",
       "      <td>583</td>\n",
       "      <td>The Big Gundown</td>\n",
       "      <td>200</td>\n",
       "      <td>2018-11-15 00:41:21</td>\n",
       "      <td>\"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/5...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Train</td>\n",
       "      <td>Logged In</td>\n",
       "      <td>Ryan</td>\n",
       "      <td>M</td>\n",
       "      <td>2</td>\n",
       "      <td>Smith</td>\n",
       "      <td>205.45261</td>\n",
       "      <td>free</td>\n",
       "      <td>San Jose-Sunnyvale-Santa Clara, CA</td>\n",
       "      <td>PUT</td>\n",
       "      <td>NextSong</td>\n",
       "      <td>None</td>\n",
       "      <td>583</td>\n",
       "      <td>Marry Me</td>\n",
       "      <td>200</td>\n",
       "      <td>2018-11-15 00:45:41</td>\n",
       "      <td>\"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/5...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        artist       auth firstName gender  itemInSession lastName     length  \\\n",
       "0     Harmonia  Logged In      Ryan      M              0    Smith  655.77751   \n",
       "1  The Prodigy  Logged In      Ryan      M              1    Smith  260.07465   \n",
       "2        Train  Logged In      Ryan      M              2    Smith  205.45261   \n",
       "\n",
       "  level                            location method      page registration  \\\n",
       "0  free  San Jose-Sunnyvale-Santa Clara, CA    PUT  NextSong         None   \n",
       "1  free  San Jose-Sunnyvale-Santa Clara, CA    PUT  NextSong         None   \n",
       "2  free  San Jose-Sunnyvale-Santa Clara, CA    PUT  NextSong         None   \n",
       "\n",
       "   sessionId             song  status                   ts  \\\n",
       "0        583    Sehr kosmisch     200  2018-11-15 00:30:26   \n",
       "1        583  The Big Gundown     200  2018-11-15 00:41:21   \n",
       "2        583         Marry Me     200  2018-11-15 00:45:41   \n",
       "\n",
       "                                           userAgent  userId  \n",
       "0  \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/5...     NaN  \n",
       "1  \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/5...     NaN  \n",
       "2  \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/5...     NaN  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fixing the timestamp columns\n",
    "df_logs = df_logs.withColumn('ts', from_unixtime(df_logs[\"ts\"]/1000))\n",
    "df_logs = df_logs.withColumn('registration', from_unixtime(df_logs[\"registration\"]/1000))\n",
    "df_logs.limit(3).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- artist: string (nullable = true)\n",
      " |-- auth: string (nullable = true)\n",
      " |-- firstName: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- itemInSession: integer (nullable = true)\n",
      " |-- lastName: string (nullable = true)\n",
      " |-- length: double (nullable = true)\n",
      " |-- level: string (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- method: string (nullable = true)\n",
      " |-- page: string (nullable = true)\n",
      " |-- registration: string (nullable = true)\n",
      " |-- sessionId: integer (nullable = true)\n",
      " |-- song: string (nullable = true)\n",
      " |-- status: integer (nullable = true)\n",
      " |-- ts: string (nullable = true)\n",
      " |-- userAgent: string (nullable = true)\n",
      " |-- userId: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_logs.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+----------+------+-------------+--------+---------+-----+--------------------+------+--------+------------+---------+--------------------+------+-------------------+--------------------+------+\n",
      "|              artist|      auth|first_name|gender|itemInSession|lastName|   length|level|            location|method|    page|registration|sessionId|                song|status|                 ts|           userAgent|userId|\n",
      "+--------------------+----------+----------+------+-------------+--------+---------+-----+--------------------+------+--------+------------+---------+--------------------+------+-------------------+--------------------+------+\n",
      "|            Harmonia| Logged In|      Ryan|     M|            0|   Smith|655.77751| free|San Jose-Sunnyval...|   PUT|NextSong|        null|      583|       Sehr kosmisch|   200|2018-11-15 00:30:26|\"Mozilla/5.0 (X11...|  null|\n",
      "|         The Prodigy| Logged In|      Ryan|     M|            1|   Smith|260.07465| free|San Jose-Sunnyval...|   PUT|NextSong|        null|      583|     The Big Gundown|   200|2018-11-15 00:41:21|\"Mozilla/5.0 (X11...|  null|\n",
      "|               Train| Logged In|      Ryan|     M|            2|   Smith|205.45261| free|San Jose-Sunnyval...|   PUT|NextSong|        null|      583|            Marry Me|   200|2018-11-15 00:45:41|\"Mozilla/5.0 (X11...|  null|\n",
      "|                null| Logged In|     Wyatt|     M|            0|   Scott|     null| free|Eureka-Arcata-For...|   GET|    Home|        null|      563|                null|   200|2018-11-15 01:57:51|Mozilla/5.0 (Wind...|  null|\n",
      "|                null| Logged In|    Austin|     M|            0| Rosales|     null| free|New York-Newark-J...|   GET|    Home|        null|      521|                null|   200|2018-11-15 03:29:37|Mozilla/5.0 (Wind...|  null|\n",
      "|         Sony Wonder| Logged In|    Samuel|     M|            0|Gonzalez|218.06975| free|Houston-The Woodl...|   PUT|NextSong|        null|      597|           Blackbird|   200|2018-11-15 03:44:09|\"Mozilla/5.0 (Mac...|  null|\n",
      "|                null| Logged In|    Samuel|     M|            1|Gonzalez|     null| free|Houston-The Woodl...|   GET|   About|        null|      597|                null|   200|2018-11-15 03:44:20|\"Mozilla/5.0 (Mac...|  null|\n",
      "|                null|Logged Out|      null|  null|            0|    null|     null| paid|                null|   PUT|   Login|        null|      602|                null|   307|2018-11-15 05:34:34|                null|  null|\n",
      "|                null| Logged In|     Tegan|     F|            1|  Levine|     null| paid|Portland-South Po...|   GET|    Home|        null|      602|                null|   200|2018-11-15 05:37:57|\"Mozilla/5.0 (Mac...|  null|\n",
      "|           Van Halen| Logged In|     Tegan|     F|            2|  Levine|289.38404| paid|Portland-South Po...|   PUT|NextSong|        null|      602|Best Of Both Worl...|   200|2018-11-15 05:48:55|\"Mozilla/5.0 (Mac...|  null|\n",
      "|           Magic Sam| Logged In|     Tegan|     F|            3|  Levine|132.04853| paid|Portland-South Po...|   PUT|NextSong|        null|      602|Call Me If You Ne...|   200|2018-11-15 05:53:44|\"Mozilla/5.0 (Mac...|  null|\n",
      "|Edward Sharpe & T...| Logged In|     Tegan|     F|            4|  Levine|306.31138| paid|Portland-South Po...|   PUT|NextSong|        null|      602|                Home|   200|2018-11-15 05:55:56|\"Mozilla/5.0 (Mac...|  null|\n",
      "|Usher featuring w...| Logged In|     Tegan|     F|            5|  Levine|395.72853| paid|Portland-South Po...|   PUT|NextSong|        null|      602|                 OMG|   200|2018-11-15 06:01:02|\"Mozilla/5.0 (Mac...|  null|\n",
      "|                null| Logged In|     Tegan|     F|            6|  Levine|     null| paid|Portland-South Po...|   GET|    Home|        null|      602|                null|   200|2018-11-15 06:01:53|\"Mozilla/5.0 (Mac...|  null|\n",
      "|         Helen Reddy| Logged In|     Tegan|     F|            7|  Levine|176.50893| paid|Portland-South Po...|   PUT|NextSong|        null|      602| Candle On The Water|   200|2018-11-15 06:07:37|\"Mozilla/5.0 (Mac...|  null|\n",
      "|        Taylor Swift| Logged In|     Tegan|     F|            8|  Levine|201.06404| paid|Portland-South Po...|   PUT|NextSong|        null|      602|            Our Song|   200|2018-11-15 06:10:33|\"Mozilla/5.0 (Mac...|  null|\n",
      "|           Sean Paul| Logged In|     Tegan|     F|            9|  Levine|245.34159| paid|Portland-South Po...|   PUT|NextSong|        null|      602|Baby Boy [feat. B...|   200|2018-11-15 06:13:54|\"Mozilla/5.0 (Mac...|  null|\n",
      "|         Soundgarden| Logged In|      Lily|     F|            0|    Koch|272.19546| paid|Chicago-Napervill...|   PUT|NextSong|        null|      582|      Black Hole Sun|   200|2018-11-15 06:14:16|\"Mozilla/5.0 (X11...|  null|\n",
      "|         The Killers| Logged In|     Tegan|     F|           10|  Levine|360.75057| paid|Portland-South Po...|   PUT|NextSong|        null|      602|               Human|   200|2018-11-15 06:17:59|\"Mozilla/5.0 (Mac...|  null|\n",
      "|       Amy Winehouse| Logged In|      Lily|     F|            1|    Koch|165.11955| paid|Chicago-Napervill...|   PUT|NextSong|        null|      582|            Addicted|   200|2018-11-15 06:18:48|\"Mozilla/5.0 (X11...|  null|\n",
      "+--------------------+----------+----------+------+-------------+--------+---------+-----+--------------------+------+--------+------------+---------+--------------------+------+-------------------+--------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# renaming from camel case to  snake case\n",
    "df_logs = (\n",
    "    df_logs\n",
    "    .withColumnRenamed('firstName', 'first_name')\n",
    "    .withColumnRenamed('lastName', 'last_name')\n",
    "    .withColumnRenamed('userId', 'user_id')\n",
    "    .withColumnRenamed('itemInSession','item_in_session')\n",
    "    .withColumnRenamed('sessionId','session_id')\n",
    "    .withColumnRenamed('userAgent', 'user_agent')\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Songplay table\n",
    "\n",
    "* songplays - records in log data associated with song plays i.e. records with page `NextSong`\n",
    "    * songplay_id, \n",
    "    * start_time, \n",
    "    * user_id, \n",
    "    * level, \n",
    "    * song_id, \n",
    "    * artist_id, \n",
    "    * session_id, \n",
    "    * location, \n",
    "    * user_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# the full table will requires a join. We can then select a subset of the columns and filter on the page.\n",
    "# to later join it with the songs table\n",
    "\n",
    "songplay_table = (\n",
    "    df_logs\n",
    "    .filter(f.lower(df_logs[\"page\"]) == \"nextsong\")\n",
    "    .select('ts', 'userId',  'level', 'song', 'artist', 'sessionId', 'location', 'userAgent')\n",
    "    .join(df_songs, on = df_logs[\"song\"] == df_songs[\"title\"], how = \"inner\")\n",
    "    .withColumnsRenamed(\n",
    "        {\n",
    "            \"ts\": \"start_time\",\n",
    "            \"userId\": \"user_id\",\n",
    "            \"sessionId\": \"session_id\",\n",
    "            \"userAgent\": \"user_agent\" \n",
    "        }\n",
    "    ).withColumn('songplay_id', f.monotonically_increasing_id())\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Users Table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_table = (\n",
    "    df_logs.select('userId', 'first')\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
